{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "def create_connection(db_file):\n",
    "    try:\n",
    "        conn = sqlite3.connect(db_file)\n",
    "        return conn\n",
    "    except sqlite3.Error as e:\n",
    "        print(e)\n",
    "    return None\n",
    "\n",
    "def create_tables(conn):\n",
    "    try:\n",
    "        cur = conn.cursor()\n",
    "        cur.execute('''\n",
    "            CREATE TABLE IF NOT EXISTS location (\n",
    "                location_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                location_abbr TEXT,\n",
    "                location_desc TEXT,\n",
    "                geo_location TEXT\n",
    "            )\n",
    "        ''')\n",
    "        cur.execute('''\n",
    "            CREATE TABLE IF NOT EXISTS topic_type (\n",
    "                topic_type_id TEXT PRIMARY KEY,\n",
    "                topic_type TEXT\n",
    "            )\n",
    "        ''')\n",
    "        cur.execute('''\n",
    "            CREATE TABLE IF NOT EXISTS topic (\n",
    "                topic_id TEXT PRIMARY KEY,\n",
    "                topic_type_id TEXT,\n",
    "                topic_desc TEXT,\n",
    "                FOREIGN KEY (topic_type_id) REFERENCES topic_type (topic_type_id)\n",
    "            )\n",
    "        ''')\n",
    "        cur.execute('''\n",
    "            CREATE TABLE IF NOT EXISTS measure (\n",
    "                measure_id TEXT PRIMARY KEY,\n",
    "                measure_desc TEXT\n",
    "            )\n",
    "        ''')\n",
    "        cur.execute('''\n",
    "            CREATE TABLE IF NOT EXISTS data_source (\n",
    "                id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                data_source TEXT\n",
    "            )\n",
    "        ''')\n",
    "        cur.execute('''\n",
    "            CREATE TABLE IF NOT EXISTS response (\n",
    "                id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                response TEXT\n",
    "            )\n",
    "        ''')\n",
    "        cur.execute('''\n",
    "            CREATE TABLE IF NOT EXISTS data_footnote (\n",
    "                id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                data_value_footnote_symbol TEXT,\n",
    "                data_value_footnote TEXT\n",
    "            )\n",
    "        ''')\n",
    "        cur.execute('''\n",
    "            CREATE TABLE IF NOT EXISTS gender (\n",
    "                id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                gender TEXT\n",
    "            )\n",
    "        ''')\n",
    "        cur.execute('''\n",
    "            CREATE TABLE IF NOT EXISTS race (\n",
    "                id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                race TEXT\n",
    "            )\n",
    "        ''')\n",
    "        cur.execute('''\n",
    "            CREATE TABLE IF NOT EXISTS age (\n",
    "                id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                age TEXT\n",
    "            )\n",
    "        ''')\n",
    "        cur.execute('''\n",
    "            CREATE TABLE IF NOT EXISTS education (\n",
    "                id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                education TEXT\n",
    "            )\n",
    "        ''')\n",
    "        cur.execute('''\n",
    "            CREATE TABLE IF NOT EXISTS data_value (\n",
    "                year INTEGER,\n",
    "                sub_measure_id TEXT,\n",
    "                data_value_unit TEXT,\n",
    "                data_value_type TEXT,\n",
    "                data_value REAL,\n",
    "                data_value_std_err REAL,\n",
    "                low_confidence_limit REAL,\n",
    "                high_confidence_limit REAL,\n",
    "                sample_size INTEGER,\n",
    "                stratification_id1 TEXT,\n",
    "                stratification_id2 TEXT,\n",
    "                stratification_id3 TEXT,\n",
    "                stratification_id4 TEXT,\n",
    "                display_order INTEGER,\n",
    "                location_id INTEGER,\n",
    "                topic_type_id TEXT,\n",
    "                topic_id TEXT,\n",
    "                measure_id TEXT,\n",
    "                data_source_id INTEGER,\n",
    "                response_id INTEGER,\n",
    "                data_footnote_id INTEGER,\n",
    "                gender_id INTEGER,\n",
    "                race_id INTEGER,\n",
    "                age_id INTEGER,\n",
    "                education_id INTEGER,\n",
    "                FOREIGN KEY (location_id) REFERENCES location(location_id),\n",
    "                FOREIGN KEY (topic_type_id) REFERENCES topic_type(topic_type_id),\n",
    "                FOREIGN KEY (topic_id) REFERENCES topic(topic_id),\n",
    "                FOREIGN KEY (measure_id) REFERENCES measure(measure_id),\n",
    "                FOREIGN KEY (data_source_id) REFERENCES data_source(id),\n",
    "                FOREIGN KEY (response_id) REFERENCES response(id),\n",
    "                FOREIGN KEY (data_footnote_id) REFERENCES data_footnote(id),\n",
    "                FOREIGN KEY (gender_id) REFERENCES gender(id),\n",
    "                FOREIGN KEY (race_id) REFERENCES race(id),\n",
    "                FOREIGN KEY (age_id) REFERENCES age(id),\n",
    "                FOREIGN KEY (education_id) REFERENCES education(id)\n",
    "            )\n",
    "        ''')\n",
    "        conn.commit()\n",
    "    except sqlite3.Error as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "def create_connection(db_file):\n",
    "    try:\n",
    "        conn = sqlite3.connect(db_file)\n",
    "        return conn\n",
    "    except sqlite3.Error as e:\n",
    "        print(e)\n",
    "    return None\n",
    "\n",
    "def create_tables(conn):\n",
    "    try:\n",
    "        cur = conn.cursor()\n",
    "        cur.execute('''\n",
    "            CREATE TABLE IF NOT EXISTS location (\n",
    "                location_id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                location_abbr TEXT,\n",
    "                location_desc TEXT,\n",
    "                geo_location TEXT\n",
    "            )\n",
    "        ''')\n",
    "        cur.execute('''\n",
    "            CREATE TABLE IF NOT EXISTS topic_type (\n",
    "                topic_type_id TEXT PRIMARY KEY,\n",
    "                topic_type TEXT\n",
    "            )\n",
    "        ''')\n",
    "        cur.execute('''\n",
    "            CREATE TABLE IF NOT EXISTS topic (\n",
    "                topic_id TEXT PRIMARY KEY,\n",
    "                topic_type_id TEXT,\n",
    "                topic_desc TEXT,\n",
    "                FOREIGN KEY (topic_type_id) REFERENCES topic_type (topic_type_id)\n",
    "            )\n",
    "        ''')\n",
    "        cur.execute('''\n",
    "            CREATE TABLE IF NOT EXISTS measure (\n",
    "                measure_id TEXT PRIMARY KEY,\n",
    "                measure_desc TEXT\n",
    "            )\n",
    "        ''')\n",
    "        cur.execute('''\n",
    "            CREATE TABLE IF NOT EXISTS data_source (\n",
    "                id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                data_source TEXT\n",
    "            )\n",
    "        ''')\n",
    "        cur.execute('''\n",
    "            CREATE TABLE IF NOT EXISTS response (\n",
    "                id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                response TEXT\n",
    "            )\n",
    "        ''')\n",
    "        cur.execute('''\n",
    "            CREATE TABLE IF NOT EXISTS data_footnote (\n",
    "                id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                data_value_footnote_symbol TEXT,\n",
    "                data_value_footnote TEXT\n",
    "            )\n",
    "        ''')\n",
    "        cur.execute('''\n",
    "            CREATE TABLE IF NOT EXISTS gender (\n",
    "                id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                gender TEXT\n",
    "            )\n",
    "        ''')\n",
    "        cur.execute('''\n",
    "            CREATE TABLE IF NOT EXISTS race (\n",
    "                id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                race TEXT\n",
    "            )\n",
    "        ''')\n",
    "        cur.execute('''\n",
    "            CREATE TABLE IF NOT EXISTS age (\n",
    "                id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                age TEXT\n",
    "            )\n",
    "        ''')\n",
    "        cur.execute('''\n",
    "            CREATE TABLE IF NOT EXISTS education (\n",
    "                id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "                education TEXT\n",
    "            )\n",
    "        ''')\n",
    "        cur.execute('''\n",
    "            CREATE TABLE IF NOT EXISTS data_value (\n",
    "                year INTEGER,\n",
    "                sub_measure_id TEXT,\n",
    "                data_value_unit TEXT,\n",
    "                data_value_type TEXT,\n",
    "                data_value REAL,\n",
    "                data_value_std_err REAL,\n",
    "                low_confidence_limit REAL,\n",
    "                high_confidence_limit REAL,\n",
    "                sample_size INTEGER,\n",
    "                stratification_id1 TEXT,\n",
    "                stratification_id2 TEXT,\n",
    "                stratification_id3 TEXT,\n",
    "                stratification_id4 TEXT,\n",
    "                display_order INTEGER,\n",
    "                location_id INTEGER,\n",
    "                topic_type_id TEXT,\n",
    "                topic_id TEXT,\n",
    "                measure_id TEXT,\n",
    "                data_source_id INTEGER,\n",
    "                response_id INTEGER,\n",
    "                data_footnote_id INTEGER,\n",
    "                gender_id INTEGER,\n",
    "                race_id INTEGER,\n",
    "                age_id INTEGER,\n",
    "                education_id INTEGER,\n",
    "                FOREIGN KEY (location_id) REFERENCES location(location_id),\n",
    "                FOREIGN KEY (topic_type_id) REFERENCES topic_type(topic_type_id),\n",
    "                FOREIGN KEY (topic_id) REFERENCES topic(topic_id),\n",
    "                FOREIGN KEY (measure_id) REFERENCES measure(measure_id),\n",
    "                FOREIGN KEY (data_source_id) REFERENCES data_source(id),\n",
    "                FOREIGN KEY (response_id) REFERENCES response(id),\n",
    "                FOREIGN KEY (data_footnote_id) REFERENCES data_footnote(id),\n",
    "                FOREIGN KEY (gender_id) REFERENCES gender(id),\n",
    "                FOREIGN KEY (race_id) REFERENCES race(id),\n",
    "                FOREIGN KEY (age_id) REFERENCES age(id),\n",
    "                FOREIGN KEY (education_id) REFERENCES education(id)\n",
    "            )\n",
    "        ''')\n",
    "        conn.commit()\n",
    "    except sqlite3.Error as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_from_db(db_file):\n",
    "    conn = create_connection(db_file)\n",
    "    if conn is not None:\n",
    "        try:\n",
    "            query = \"\"\"\n",
    "            SELECT dv.YEAR as year, dv.Data_Value as data_value, loc.location_desc, tt.topic_type, t.topic_desc,\n",
    "                   m.measure_desc, ds.data_source, r.Response as response, df.Data_Value_Footnote as data_value_footnote,\n",
    "                   g.Gender as gender, ra.Race as race, a.Age as age, e.Education as education\n",
    "            FROM data_value AS dv\n",
    "            JOIN location AS loc ON dv.location_id = loc.location_id\n",
    "            JOIN topic_type AS tt ON dv.topic_type_id = tt.topic_type_id\n",
    "            JOIN topic AS t ON dv.topic_id = t.topic_id\n",
    "            JOIN measure AS m ON dv.measure_id = m.measure_id\n",
    "            JOIN data_source AS ds ON dv.data_source_id = ds.id\n",
    "            JOIN response AS r ON dv.response_id = r.id\n",
    "            JOIN data_footnote AS df ON dv.data_footnote_id = df.id\n",
    "            JOIN gender AS g ON dv.gender_id = g.id\n",
    "            JOIN race AS ra ON dv.race_id = ra.id\n",
    "            JOIN age AS a ON dv.age_id = a.id\n",
    "            JOIN education AS e ON dv.education_id = e.id\n",
    "            \"\"\"\n",
    "            df = pd.read_sql(query, conn)\n",
    "            conn.close()\n",
    "            return df\n",
    "        except sqlite3.Error as e:\n",
    "            print(f\"Error executing query: {e}\")\n",
    "            return pd.DataFrame()\n",
    "    else:\n",
    "        return pd.DataFrame()\n",
    "    # Load data\n",
    "\n",
    "db_file = 'tobacco_use_data.db'  # Specify your SQLite database file path\n",
    "data = load_data_from_db(db_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "data['data_value'] = imputer.fit_transform(data[['data_value']])\n",
    "\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab9452964b6a44f7813ca948bd28e81b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarize dataset:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/ydata_profiling/model/correlations.py:66: UserWarning: There was an attempt to calculate the auto correlation, but this failed.\n",
      "To hide this warning, disable the calculation\n",
      "(using `df.profile_report(correlations={\"auto\": {\"calculate\": False}})`\n",
      "If this is problematic for your use case, please report this as an issue:\n",
      "https://github.com/ydataai/ydata-profiling/issues\n",
      "(include the error message: 'could not convert string to float: 'All Ages'')\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/seaborn/matrix.py:260: FutureWarning: Format strings passed to MaskedConstant are ignored, but in future may error or produce different behavior\n",
      "  annotation = (\"{:\" + self.fmt + \"}\").format(val)\n",
      "/opt/anaconda3/lib/python3.11/site-packages/ydata_profiling/model/missing.py:78: UserWarning: There was an attempt to generate the Heatmap missing values diagrams, but this failed.\n",
      "To hide this warning, disable the calculation\n",
      "(using `df.profile_report(missing_diagrams={\"Heatmap\": False}`)\n",
      "If this is problematic for your use case, please report this as an issue:\n",
      "https://github.com/ydataai/ydata-profiling/issues\n",
      "(include the error message: 'could not convert string to float: '--'')\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d54b9257ceed47fe821be3f4631ba57c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate report structure:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e699d6aecff4256ab6e1730f7c6c940",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Render HTML:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c109f84b41c46c986f8b963ac7589fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Export report to file:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ydata_profiling import ProfileReport\n",
    "\n",
    "profile = ProfileReport(train_data, title=\"Pandas Profiling Report\", explorative=True)\n",
    "profile.to_file(\"GroupProject.html\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year                       0\n",
      "data_value                 0\n",
      "location_desc              0\n",
      "topic_type                 0\n",
      "topic_desc                 0\n",
      "measure_desc               0\n",
      "data_source                0\n",
      "response               22694\n",
      "data_value_footnote     1761\n",
      "gender                     0\n",
      "race                       0\n",
      "age                        0\n",
      "education                  0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "categorical_cols = ['location_desc', 'topic_type', 'topic_desc', 'measure_desc', 'data_source', 'response', 'data_value_footnote', 'gender', 'race', 'age', 'education']\n",
    "numerical_cols = ['year', 'data_value']\n",
    "\n",
    "# Check for null values\n",
    "print(train_data.isnull().sum())\n",
    "\n",
    "train_data[categorical_cols] = train_data[categorical_cols].astype(str)\n",
    "train_data[numerical_cols] = train_data[numerical_cols].apply(pd.to_numeric, errors='coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/r5/_bzgrbtj6tg33lk21qcyg0l80000gn/T/ipykernel_50697/2648839054.py:2: MatplotlibDeprecationWarning: Auto-close()ing of figures upon backend switching is deprecated since 3.8 and will be removed two minor releases later.  To suppress this warning, explicitly call plt.close('all') first.\n",
      "  matplotlib.use('WebAgg')\n",
      "/var/folders/r5/_bzgrbtj6tg33lk21qcyg0l80000gn/T/ipykernel_50697/2648839054.py:20: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data['data_value'].fillna(data['data_value'].median(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('WebAgg') \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def load_data():\n",
    "    \n",
    "    data = pd.DataFrame({\n",
    "        'location_desc': ['Location1', 'Location2', 'Location1', 'Location2'],\n",
    "        'topic_type': ['Type1', 'Type2', 'Type1', 'Type2'],\n",
    "        'year': [2001, 2002, 2001, 2002],\n",
    "        'data_value': [10, None, 20, 30]\n",
    "    })\n",
    "    return data\n",
    "\n",
    "data = load_data()\n",
    "\n",
    "data['data_value'].fillna(data['data_value'].median(), inplace=True)\n",
    "\n",
    "# Splitting the data into train and test sets\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "categorical_cols = ['location_desc', 'topic_type']\n",
    "numerical_cols = ['year', 'data_value']\n",
    "\n",
    "clean_numerical_data = train_data[numerical_cols].dropna().loc[:, (train_data[numerical_cols].var() != 0)]\n",
    "\n",
    "if not clean_numerical_data.empty and clean_numerical_data.shape[1] > 1:\n",
    "    correlation_matrix = clean_numerical_data.corr()\n",
    "    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n",
    "    plt.title('Numerical Feature Correlation Heatmap')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Insufficient data for a meaningful correlation heatmap.\")\n",
    "\n",
    "if 'data_value' in train_data.columns and all(col in train_data.columns for col in categorical_cols):\n",
    "    for col in categorical_cols:\n",
    "        if train_data[col].nunique() < 20: \n",
    "            plt.figure(figsize=(10, 6))  \n",
    "            sns.violinplot(x=col, y='data_value', data=train_data)\n",
    "            plt.title(f'Violin Plot for {col}')\n",
    "            plt.xticks(rotation=45)\n",
    "            plt.show()\n",
    "        else:\n",
    "            print(f\"Skipping {col} due to too many unique categories ({train_data[col].nunique()}).\")\n",
    "else:\n",
    "    missing_cols = [col for col in categorical_cols if col not in train_data.columns]\n",
    "    print(\"Some categorical columns or 'data_value' column are missing:\", missing_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPreprocessor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, categorical_cols, numerical_cols):\n",
    "        self.categorical_cols = categorical_cols\n",
    "        self.numerical_cols = numerical_cols\n",
    "        self.imputer_num = SimpleImputer(strategy='mean')\n",
    "        self.imputer_cat = SimpleImputer(strategy='most_frequent')\n",
    "        self.encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "        self.scaler = StandardScaler()\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.imputer_num.fit(X[self.numerical_cols])\n",
    "        self.imputer_cat.fit(X[self.categorical_cols])\n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from dagshub import dagshub_logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No NaN values in the target variable.\n",
      "MAE: 10.000000000000004\n",
      "MSE: 100.00000000000007\n",
      "RMSE: 10.000000000000004\n"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "if not data.empty:\n",
    "    \n",
    "    X = data.drop(columns=[\"data_value\"])\n",
    "    y = data[\"data_value\"]\n",
    "\n",
    "    \n",
    "    if y.isnull().any():\n",
    "        print(\"Warning: NaN values found in target variable. Removing these records.\")\n",
    "        \n",
    "        combined = pd.concat([X, y], axis=1)\n",
    "        clean_combined = combined.dropna(subset=[\"data_value\"])\n",
    "        X = clean_combined.drop(columns=[\"data_value\"])\n",
    "        y = clean_combined[\"data_value\"]\n",
    "    else:\n",
    "        print(\"No NaN values in the target variable.\")\n",
    "\n",
    "    \n",
    "    categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "    preprocess = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', StandardScaler(), numerical_cols),\n",
    "            ('cat', Pipeline(steps=[\n",
    "                ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "                ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "            ]), categorical_cols)\n",
    "        ], remainder='passthrough')\n",
    "\n",
    "    X[categorical_cols] = X[categorical_cols].astype(str)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    model_pipeline = Pipeline([\n",
    "        ('preprocessor', preprocess),\n",
    "        ('regressor', LinearRegression())\n",
    "    ])\n",
    "\n",
    "    model_pipeline.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model_pipeline.predict(X_test)\n",
    "\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "\n",
    "    print(f\"MAE: {mae}\")\n",
    "    print(f\"MSE: {mse}\")\n",
    "    print(f\"RMSE: {rmse}\")\n",
    "else:\n",
    "    print(\"Data not loaded or empty.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Regressor - MAE: 5.800000000000004, MSE: 33.64000000000005, RMSE: 5.800000000000004\n",
      "Gradient Boosting Regressor - MAE: 9.999734386011145, MSE: 99.9946877907737, RMSE: 9.999734386011145\n",
      "Support Vector Regressor - MAE: 1.958016943853707, MSE: 3.8338303524182105, RMSE: 1.958016943853707\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Pipeline(steps=[('preprocessor',\n",
       "                  ColumnTransformer(remainder='passthrough',\n",
       "                                    transformers=[('num', StandardScaler(),\n",
       "                                                   ['year']),\n",
       "                                                  ('cat',\n",
       "                                                   Pipeline(steps=[('imputer',\n",
       "                                                                    SimpleImputer(fill_value='missing',\n",
       "                                                                                  strategy='constant')),\n",
       "                                                                   ('onehot',\n",
       "                                                                    OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                   ['location_desc',\n",
       "                                                    'topic_type'])])),\n",
       "                 ('regressor', SVR())]),\n",
       " 1.958016943853707,\n",
       " 3.8338303524182105,\n",
       " 1.958016943853707)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def evaluate_model(model, model_name, X_train, X_test, y_train, y_test):\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessor', preprocess),\n",
    "        ('regressor', model)\n",
    "    ])\n",
    "    \n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    \n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = mse ** 0.5\n",
    "    \n",
    "    print(f\"{model_name} - MAE: {mae}, MSE: {mse}, RMSE: {rmse}\")\n",
    "\n",
    "    return pipeline, mae, mse, rmse\n",
    "\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "gb_model = GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
    "svr_model = SVR()\n",
    "\n",
    "evaluate_model(rf_model, \"Random Forest Regressor\", X_train, X_test, y_train, y_test)\n",
    "evaluate_model(gb_model, \"Gradient Boosting Regressor\", X_train, X_test, y_train, y_test)\n",
    "evaluate_model(svr_model, \"Support Vector Regressor\", X_train, X_test, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import dagshub\n",
    "from mlflow.sklearn import log_model\n",
    "import os\n",
    "\n",
    "os.environ['MLFLOW_TRACKING_USERNAME'] = 'lollaadityasrivatsav'\n",
    "os.environ['MLFLOW_TRACKING_PASSWORD'] = 'Srivatsav@04'\n",
    "\n",
    "def evaluate_and_log_model(model, model_name, X_train, X_test, y_train, y_test):\n",
    "    mlflow.set_tracking_uri(\"https://dagshub.com/lollaadityasrivatsav/Python_Group_Project.mlflow\")\n",
    "\n",
    "    with mlflow.start_run(run_name=model_name):\n",
    "        \n",
    "        pipeline, mae, mse, rmse = evaluate_model(model, X_train, X_test, y_train, y_test)\n",
    "\n",
    "        mlflow.log_params({\"model_type\": model_name})\n",
    "        mlflow.log_metric(\"MAE\", mae)\n",
    "        mlflow.log_metric(\"MSE\", mse)\n",
    "        mlflow.log_metric(\"RMSE\", rmse)\n",
    "        \n",
    "        log_model(pipeline, \"model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 33.64000000000005\n"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Identify categorical columns (This is just an example; adjust based on your dataset)\n",
    "categorical_features = ['location_desc', 'topic_type']  # Update this with your actual categorical columns\n",
    "\n",
    "# Create a column transformer with OneHotEncoder for categorical features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ],\n",
    "    remainder='passthrough'  # Leave other types of columns unchanged\n",
    ")\n",
    "\n",
    "# Create a pipeline that includes preprocessing and the model\n",
    "model_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', RandomForestRegressor(n_estimators=100, random_state=42))\n",
    "])\n",
    "\n",
    "# Fit the pipeline on the training data\n",
    "model_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "predictions = model_pipeline.predict(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "print(f'Mean Squared Error: {mse}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
